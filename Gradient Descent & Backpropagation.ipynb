{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset and do our preprocessing:\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28 is the original 2D image. We transform our 2D dataset to 1D\n",
    "output_dim = nb_classes = 10 # 10 digits --> 10 classes\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim) # 60000 is the amount of train entries\n",
    "X_test = X_test.reshape(10000, input_dim) # 10000 is the amount of test entries\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # normalize each vector by dividing each element by 255 (this is the maximum value of the RGB color scale)\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot code our target variable using to_categorical function of Keras' utils module\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the shape of X_train. We have 60000 rows and 784 features\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at some of the original images:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 8 as the mini batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.3647 - accuracy: 0.8969\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 19s 322us/sample - loss: 0.1686 - accuracy: 0.9503\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 22s 371us/sample - loss: 0.1240 - accuracy: 0.9636- los\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 19s 309us/sample - loss: 0.0980 - accuracy: 0.9707\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.0798 - accuracy: 0.9765\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 18s 299us/sample - loss: 0.0669 - accuracy: 0.9796\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 16s 273us/sample - loss: 0.0567 - accuracy: 0.9834\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0487 - accuracy: 0.9856\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0426 - accuracy: 0.9873\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 18s 296us/sample - loss: 0.0362 - accuracy: 0.9898\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.0311 - accuracy: 0.9916\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 20s 330us/sample - loss: 0.0276 - accuracy: 0.9924\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 25s 420us/sample - loss: 0.0238 - accuracy: 0.9937\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 18s 296us/sample - loss: 0.0202 - accuracy: 0.9949\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.0172 - accuracy: 0.9961\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.0152 - accuracy: 0.9963\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.0133 - accuracy: 0.9970\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 20s 338us/sample - loss: 0.0114 - accuracy: 0.9978\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 21s 358us/sample - loss: 0.0097 - accuracy: 0.9984\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 19s 319us/sample - loss: 0.0083 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144768710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# our first dense layer\n",
    "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.07260856416276947\n",
      "Test accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 128 as the mini batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 1.1541 - accuracy: 0.7183\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4786 - accuracy: 0.8741\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3815 - accuracy: 0.8946\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3388 - accuracy: 0.9043\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3115 - accuracy: 0.9111\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2915 - accuracy: 0.9164\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2751 - accuracy: 0.9218\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2609 - accuracy: 0.9259\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2490 - accuracy: 0.9293\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2378 - accuracy: 0.9319\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2281 - accuracy: 0.9348\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2190 - accuracy: 0.9378\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2109 - accuracy: 0.9399\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2031 - accuracy: 0.9423\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1962 - accuracy: 0.9446\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1897 - accuracy: 0.9458\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1836 - accuracy: 0.9477\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1778 - accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1724 - accuracy: 0.9514\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1671 - accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15000d350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model1 = Sequential()\n",
    "# our first dense layer\n",
    "model1.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model1.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model1.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model1.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16940312106907368\n",
      "Test accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using the full sample as the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 2.3755 - accuracy: 0.0998\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3656 - accuracy: 0.1004\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3562 - accuracy: 0.1010\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3473 - accuracy: 0.1022\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3388 - accuracy: 0.1038\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3306 - accuracy: 0.1055\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.3227 - accuracy: 0.1077\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3151 - accuracy: 0.1104\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3078 - accuracy: 0.1143\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3007 - accuracy: 0.1189\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2938 - accuracy: 0.1247\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2871 - accuracy: 0.1305\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2805 - accuracy: 0.1371\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2741 - accuracy: 0.1434\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2679 - accuracy: 0.1505\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2617 - accuracy: 0.1585\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2557 - accuracy: 0.1659\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2498 - accuracy: 0.1748\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2440 - accuracy: 0.1833\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2383 - accuracy: 0.1914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15028f650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "# our first dense layer\n",
    "model2.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model2.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model2.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model2.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 2.2347884399414064\n",
      "Test accuracy: 0.198\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 0.01 as the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "sgd_001 = optimizers.SGD(lr=0.01)\n",
    "sgd_100 = optimizers.SGD(lr=100)\n",
    "sgd_00000001 = optimizers.SGD(lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.2397 - accuracy: 0.6780\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.5040 - accuracy: 0.8684\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3911 - accuracy: 0.8928\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3439 - accuracy: 0.9027\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3155 - accuracy: 0.9109\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2947 - accuracy: 0.9173\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2784 - accuracy: 0.9211\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2645 - accuracy: 0.9248\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2525 - accuracy: 0.9284\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2418 - accuracy: 0.9315\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2317 - accuracy: 0.9343\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2225 - accuracy: 0.9366\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2139 - accuracy: 0.9394s - loss:\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2060 - accuracy: 0.9410\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1986 - accuracy: 0.9431\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1916 - accuracy: 0.9453\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1850 - accuracy: 0.9471\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1790 - accuracy: 0.9486\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1734 - accuracy: 0.9503\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1678 - accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15114bf90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model3 = Sequential()\n",
    "# our first dense layer\n",
    "model3.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model3.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model3.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model3.compile(optimizer=sgd_001, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model3.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16598114916086196\n",
      "Test accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 100 as the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 110325589.2361 - accuracy: 0.1017\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 40.1435 - accuracy: 0.1007\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 40.1978 - accuracy: 0.0988\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 39.6207 - accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 40.7930 - accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 39.3494 - accuracy: 0.1026\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 40.0644 - accuracy: 0.1006\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 41.1019 - accuracy: 0.0979\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 40.0284 - accuracy: 0.0993\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 40.4798 - accuracy: 0.0982\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 40.5576 - accuracy: 0.1003\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 40.0494 - accuracy: 0.1009\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 40.5274 - accuracy: 0.0995\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 40.5971 - accuracy: 0.1005\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 40.4405 - accuracy: 0.0979\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 40.4655 - accuracy: 0.1015\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 40.0168 - accuracy: 0.1008\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 40.7170 - accuracy: 0.0990\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 39.4014 - accuracy: 0.1017\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 40.3583 - accuracy: 0.0996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1517fd090>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model4 = Sequential()\n",
    "# our first dense layer\n",
    "model4.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model4.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model4.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model4.compile(optimizer=sgd_100, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model4.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 39.684728338623046\n",
      "Test accuracy: 0.0974\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model4.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 0.0000001 as the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 2.3122 - accuracy: 0.0970\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 2.3121 - accuracy: 0.0970\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 2.3120 - accuracy: 0.0970\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 2.3120 - accuracy: 0.0970\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 2.3120 - accuracy: 0.0970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1516a13d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model5 = Sequential()\n",
    "# our first dense layer\n",
    "model5.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model5.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model5.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model5.compile(optimizer=sgd_00000001, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model5.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 2.3115089763641357\n",
      "Test accuracy: 0.0984\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model5.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
