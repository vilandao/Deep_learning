{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset and do our preprocessing:\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28 is the original 2D image. We transform our 2D dataset to 1D\n",
    "output_dim = nb_classes = 10 # 10 digits --> 10 classes\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim) # 60000 is the amount of train entries\n",
    "X_test = X_test.reshape(10000, input_dim) # 10000 is the amount of test entries\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # normalize each vector by dividing each element by 255 (this is the maximum value of the RGB color scale)\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot code our target variable using to_categorical function of Keras' utils module\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the shape of X_train. We have 60000 rows and 784 features\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at some of the original images:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using tanh activation function for each layer using categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 1.0221 - accuracy: 0.7462\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5193 - accuracy: 0.8711\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4202 - accuracy: 0.8891\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3733 - accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3446 - accuracy: 0.9046\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3242 - accuracy: 0.9089\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3087 - accuracy: 0.9125\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2958 - accuracy: 0.9157\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2849 - accuracy: 0.9186\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2753 - accuracy: 0.9214\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2667 - accuracy: 0.9237\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2589 - accuracy: 0.9262\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2518 - accuracy: 0.9283\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2449 - accuracy: 0.9297\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2385 - accuracy: 0.9317\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2324 - accuracy: 0.9335\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2268 - accuracy: 0.9352\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2213 - accuracy: 0.9372\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2161 - accuracy: 0.9385\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2110 - accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148fd1590>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# our first dense layer\n",
    "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "# our second dense layer\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "# last layer is the output layer.\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.2095155075162649\n",
      "Test accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer using categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 2.2891 - accuracy: 0.1957\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 2.2279 - accuracy: 0.3525\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 2.1647 - accuracy: 0.4743\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 2.0756 - accuracy: 0.5458\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.9478 - accuracy: 0.5849\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.7776 - accuracy: 0.6252\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 1.5840 - accuracy: 0.6539\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 1.3986 - accuracy: 0.6869\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 1.2413 - accuracy: 0.7148\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 1.1147 - accuracy: 0.7379\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 1.0135 - accuracy: 0.7576\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.9312 - accuracy: 0.7736\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.8630 - accuracy: 0.7891\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.8053 - accuracy: 0.8005\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.7558 - accuracy: 0.8102\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.7130 - accuracy: 0.8207\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6755 - accuracy: 0.8289\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.6427 - accuracy: 0.8364\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.6137 - accuracy: 0.8432\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.5879 - accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1492c4110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model1 = Sequential()\n",
    "# our first dense layer\n",
    "model1.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "# our second dense layer\n",
    "model1.add(Dense(64, activation=\"sigmoid\"))\n",
    "# last layer is the output layer.\n",
    "model1.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model1.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.561860973072052\n",
      "Test accuracy: 0.8573\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using ReLU activation function for each layer using categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.2646 - accuracy: 0.6702\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.5035 - accuracy: 0.8670\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3889 - accuracy: 0.8924\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3427 - accuracy: 0.9036\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3153 - accuracy: 0.9095\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2953 - accuracy: 0.9151\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2797 - accuracy: 0.9196\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2664 - accuracy: 0.9230\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2547 - accuracy: 0.9264\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2446 - accuracy: 0.9295\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2354 - accuracy: 0.9324\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2269 - accuracy: 0.9352\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2188 - accuracy: 0.9376\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2114 - accuracy: 0.9400\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2047 - accuracy: 0.9419\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1982 - accuracy: 0.9438\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1920 - accuracy: 0.9454\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1864 - accuracy: 0.9467\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1810 - accuracy: 0.9480\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1756 - accuracy: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1552ae950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "# our first dense layer\n",
    "model2.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model2.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model2.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model2.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.17490061144530772\n",
      "Test accuracy: 0.9482\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu activation function gave us the best test score and test accuracy.\n",
    "\n",
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using tanh activation function for each layer using hinge loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.9915 - accuracy: 0.4325\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.7613 - accuracy: 0.6994\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.5773 - accuracy: 0.7849\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4647 - accuracy: 0.8421\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3897 - accuracy: 0.8661\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3424 - accuracy: 0.8772\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3110 - accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2887 - accuracy: 0.8901\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2716 - accuracy: 0.8949\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2581 - accuracy: 0.8982\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2470 - accuracy: 0.9014\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2376 - accuracy: 0.9042\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2296 - accuracy: 0.9064\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2225 - accuracy: 0.9091\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2162 - accuracy: 0.9110\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2106 - accuracy: 0.9128\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2055 - accuracy: 0.9151\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2009 - accuracy: 0.9168\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1966 - accuracy: 0.9181\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1926 - accuracy: 0.9195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155c1d090>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model3 = Sequential()\n",
    "# our first dense layer\n",
    "model3.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "# our second dense layer\n",
    "model3.add(Dense(64, activation=\"tanh\"))\n",
    "# last layer is the output layer.\n",
    "model3.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model3.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model3.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.185254743771255\n",
      "Test accuracy: 0.9221\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer using hinge loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1.0056 - accuracy: 0.1878\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 1.0029 - accuracy: 0.2573\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 1.0021 - accuracy: 0.3111\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 1.0015 - accuracy: 0.3618\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.0009 - accuracy: 0.4077\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 1.0003 - accuracy: 0.4479\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.9998 - accuracy: 0.4861\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.9994 - accuracy: 0.5175\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.9990 - accuracy: 0.5467\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.9986 - accuracy: 0.5689\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9982 - accuracy: 0.5900\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9978 - accuracy: 0.6071\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9975 - accuracy: 0.6214\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.9971 - accuracy: 0.6345\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.9968 - accuracy: 0.6463\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9964 - accuracy: 0.6571\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.9961 - accuracy: 0.6641\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9957 - accuracy: 0.6713\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.9954 - accuracy: 0.6774\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9950 - accuracy: 0.6824s - loss: 0.9950 - accuracy: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155ff12d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model4 = Sequential()\n",
    "# our first dense layer\n",
    "model4.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "# our second dense layer\n",
    "model4.add(Dense(64, activation=\"sigmoid\"))\n",
    "# last layer is the output layer.\n",
    "model4.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model4.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model4.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9946555833816528\n",
      "Test accuracy: 0.6982\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model4.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using ReLU activation function for each layer using hinge loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1.0118 - accuracy: 0.3004\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.9830 - accuracy: 0.5421\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.9161 - accuracy: 0.6442\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.7748 - accuracy: 0.7089\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.5673 - accuracy: 0.7972\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4169 - accuracy: 0.8608s - loss: 0.428\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3346 - accuracy: 0.8798\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2910 - accuracy: 0.8883\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2641 - accuracy: 0.8946\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2456 - accuracy: 0.8998\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2316 - accuracy: 0.9039\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2208 - accuracy: 0.9068\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2116 - accuracy: 0.9106\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2040 - accuracy: 0.9131\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1975 - accuracy: 0.9149\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1917 - accuracy: 0.9172\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1866 - accuracy: 0.9185\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1821 - accuracy: 0.9203\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1779 - accuracy: 0.9220\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1739 - accuracy: 0.9235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15624f210>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model5 = Sequential()\n",
    "# our first dense layer\n",
    "model5.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model5.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model5.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compiling the model:\n",
    "model5.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model5.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16725292722247542\n",
      "Test accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model5.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracies in both the training and the test sets are achieved using the ReLU function. Moreover, all accuracies for all the models are lower when we train our models using hinge loss in comparison to using cross entropy loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
