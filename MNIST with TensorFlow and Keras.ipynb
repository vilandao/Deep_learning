{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Hand written numbers MNIST using TensorFlow and Keras\n",
    "\n",
    "Throughout this kernal, we'll be using a famous optical character recognition (OCR) dataset called MNIST. This dataset comprises of 70000 grayscale images of handwritten digits. Using this dataset in deep learning research and education is classical and that's why we choose it here. In the following, we'll load the dataset and do some data preprocessing. As we'll see shortly, each image is represented as 28x28 pixel data. This is a two-dimensional vector. We'll first convert this to a vector of 784 length which will be single-dimensional. We also normalize each vector by dividing each element by 255 (this is the maximum value of the RGB color scale).\n",
    "We load the MNIST dataset using Keras' datasets module. We use mnist class from this module to load the MNIST data. \n",
    "\n",
    "Our purpose is to build a deep learning model that can predict the 10 digit numbers based on hand written images.\n",
    "\n",
    "Let's start by installing TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 120.8 MB 26 kB/s  eta 0:00:011  |██▌                             | 9.3 MB 1.2 MB/s eta 0:01:32     |███▋                            | 13.7 MB 21.4 MB/s eta 0:00:05     |████▉                           | 18.2 MB 21.4 MB/s eta 0:00:05     |███████████▍                    | 42.9 MB 15.3 MB/s eta 0:00:06     |████████████▊                   | 48.2 MB 15.3 MB/s eta 0:00:05     |████████████████▎               | 61.7 MB 25.9 MB/s eta 0:00:03     |████████████████████            | 75.4 MB 23.1 MB/s eta 0:00:02     |███████████████████████         | 87.0 MB 23.1 MB/s eta 0:00:02��███▌  | 111.3 MB 31.6 MB/s eta 0:00:01███▋  | 111.7 MB 1.9 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 4.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.28.1-cp37-cp37m-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.4 MB 50.4 MB/s eta 0:00:01   |▌                               | 440 kB 3.4 MB/s eta 0:00:09     |██████▌                         | 5.7 MB 3.4 MB/s eta 0:00:07     |███████▌                        | 6.6 MB 3.4 MB/s eta 0:00:07     |██████████████████████████▊     | 23.7 MB 50.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.13.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/vilandao/opt/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=3c4db2106af12546eec954ef9f88b740a29406737b8b841aa9399bd6a1e8b76f\n",
      "  Stored in directory: /Users/vilandao/Library/Caches/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=f0871ce2e10e0f74cf25ad63080c422c845c179341cc34aec1b7f9a5c38cd278\n",
      "  Stored in directory: /Users/vilandao/Library/Caches/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=1b1cdc451758ce23d9838dad52667e3ac8a15e4a90df0c3fe9e724002283dfa6\n",
      "  Stored in directory: /Users/vilandao/Library/Caches/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: opt-einsum, keras-applications, google-pasta, keras-preprocessing, termcolor, grpcio, absl-py, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, scipy, astor, gast, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.28.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.2.1 requests-oauthlib-1.3.0 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset and do our preprocessing:\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28 is the original 2D image. We transform our 2D dataset to 1D\n",
    "output_dim = nb_classes = 10 # 10 digits --> 10 classes\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim) # 60000 is the amount of train entries\n",
    "X_test = X_test.reshape(10000, input_dim) # 10000 is the amount of test entries\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # normalize each vector by dividing each element by 255 (this is the maximum value of the RGB color scale)\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot code our target variable using to_categorical function of Keras' utils module\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the shape of X_train. We have 60000 rows and 784 features\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAEiCAYAAACPwRUyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7RkZXkv6t8LrdsLiKARkLQhKmRsMW4wHIWgoBuTgLBRzzjGkETJOWyMGcgxeEmMxERDyCZECJqceAHZgCKoaKLSniTGrSIaPXJR0UAQtZHWDmhrGy9JDPR3/lhFXLSra1b3qrVq1uznGaMGtep765vvqu760f32rLmqtRYAAAAAhmeXWTcAAAAAwMow+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIOfHqmqD1fVf5/Bc3+jqu6oqu9W1UMmqP+1qrpmR461xF6vqKoLp7EXMB2yCOgDWQT0gSxiCAx+VkBVra+qp826j0lU1X2SnJfk51tru7XWNm21vn9VtapasxLHb639UWtth8JwVqrqEaMAXnxrVfWSWfcGi8miyc1jFiVJVZ1ZVTdW1V1V9apZ9wNLkUWTm+MsOriqPlpV366qDVX1e7PuCbYmiyY3r1mUJFX1oqr6clV9r6puqqoDZ91THxj8sHeS+yX5/KwbmRetta+MAni31tpuSX46yZYk75pxazDPZNGOuTXJbyVZN+tGYCBk0Y55W5Krk+yV5Kgkv1FVJ8y2JZhrsmgHjM6uOjnJcUl2S3J8km/MtKmeMPhZRVW1Z1VdVVVfr6pvje7/+FZlj6qq/2/0Lybvqaq9Fj3/sKr6eFVtrqrPVNVTJjzuf6qq86vqa6Pb+aPHDkzyj6OyzVX1v5Z4+tWL1r9bVYcv2vc1o+/jy1V17KLH96iqN1fVxqr6alX9YVXtuo3eXlVVbx3dv2dy/X9W1e2jvV9QVf9bVX129H3/+aLnPqqq/ldVbaqqb1TVZVX14EXrj6+qG6rqO1X1zqp6e1X94aL146vq06N9P15Vj5vk9VzC85Jc3Vpbv4PPh1Uli5bsbS6zqLV2SWvt/03ynUmfA30hi5bsbS6zKMn+SS5rrd3dWvtikmuSHLQdz4eZkUVL9jZ3WVRVuyT5/SSnt9b+oS34Ymvtm5M8f+gMflbXLkn+Z5KfSPKIJP+S5M+3qnlekv8rycOT3JXkdUlSVftl4V90/zAL/5ry0iTvqqofm+C4ZyQ5LMnBSf5Lkick+d3W2i354f+UH9xa+69LPPfIReu7tdb+fvT1E7MQSA9Nck6SN1dVjdYuGfX+6CSHJPn5JNtzquATkxyQ5DlJzh/1/7RRr79YVUeN6irJ/8jCa/Wfk6xN8qokqar7JvnLJBdn4fW6PMmz7jlAVT0+yUVJfj3JQ5K8Mcl7q+o/jdb/oqr+YsJ+nzf6nmFeyKLJzFsWwbyRRZOZhyw6P8nzquo+VfVTSQ5P8nfb8T3CLMmiyfQ9i358dHvsaED15ap69WggRGvNbcq3JOuTPG2CuoOTfGvR1x9Ocvairx+T5AdJdk3y20nestXz/ybJSYue+9+3cZwvJnn6oq9/Icn60f39k7Qka7bx3B9ZT/JrSW5d9PUDRjX7ZOG0xH9Lcv9F6ycm+dA29n9Vkrdudaz9Fq1vSvKcRV+/K8lvbmOvZya5YXT/yCRfTVKL1q9J8oej+69PcuZWz//HJEdt56/1k5N8N8lus/595+a29U0W7VRZ9NYkr5r17zk3t6Vusmj4WZTkZ7Pw0dO7Rj2/eta/79zctr7JomFn0SiHWhYGcQ8e9X1LklNm/XuvD7cVuRgUS6uqByT50yTHJNlz9PDuVbVra+3u0de3L3rKbUnuk4WJ7U8keXZV/bdF6/dJ8qEJDv3w0V6L93349n8H9/JP99xprX1/NEjeLQuT2/sk2fjD4XJ2yb2/ry53LLr/L0t8vVuSVNXDsjBtf3KS3UfH+dao7uFJvtpGKTCyuIefSHJSVZ226LH7Zvtfl5OSvKu19t3tfB7MjCya2DxlEcwdWTSxXmfR6CMvf53khVm41s8+Sa6sqjtaa85YpPdk0cR6nUWjHpLknNba5ix8DO6NSZ6e5IIJnj9oTntaXS9J8lNJnthae1B+eIpeLapZu+j+I5L8exYuSHV7FqbJD150e2Br7ewJjvu1LLyJFu/7tQl7bt0l93J7FqbJD13U54NaayvxOe//kYX+Hjd6PX81P3wtNybZb9Gpjcm9X9vbk5y11ev5gNba5ZMevKrun+TZ8TEv5o8smq6ZZhHMMVk0XbPKokcmubu1dmlr7a7W2oYkV2ThL1swD2TRdM0qi/4xC2dibe9rs1Mw+Fk596mq+y26rcnCxPNfsjB93CsLF5/a2q9W1WNGk+c/SHLlaNL81iT/rap+oap2He35lPrRC48t5fIkv1tVP1ZVD03ye6P9JvH1LPzEqkdOUtxa25jkb5OcW1UPqqpdRhf4OmrC422P3bPwMavNo8/XvmzR2t8nuTvJC6tqTVU9Iwufm73HBUleUFVPrAUPrKrjqmr37Tj+s5JszmQTfZgVWTTgLBpdT+N+Wfj/+ZrRr8eSF2qEGZNFw82iW5JUVf3y6PvbJwvXAPnMVL4rmC5ZNNAsaq19P8nbk/xWVe0++jU4JclVU/q+5prBz8p5fxYC5J7bq7JwEaz7Z2E6/IksnBa7tbdk4WJX/5SFH+H3fydJa+32JM9I8oosvNFvz8KbaJJfwz9Mcm2Szya5Mcn1o8c6jd5AZyX5WC1cWf2wCZ72vCyckvcPWTit78ok+05yvO306iSPT/LtLHyW8933LLTWfpDkf8/Cj/PbnIVJ81VZmHSntXZtFoLgz0c93pqFz8UmSarqDVX1ho7jn5Tk0q1OVYS+kUXDzqILsvDremIWLrL4L0meO51vC6ZKFg00i1pr/zza+/TRcz+d5HNZeJ2gb2TRQLNo5IVZGDp9LQtDprdl4WLRO73yd1Z2FlX1ySRvaK39z1n3Auy8ZBHQB7II6ANZtDqc8cNgVdVRVbXP6DTCk5I8LktP8AFWjCwC+kAWAX0gi2bDT/ViyH4qyTuycIX5Lyb5P0afbwVYTbII6ANZBPSBLJoBH/UCAAAAGCgf9QIAAAAYKIMfAAAAgIFa1Wv8VJXPlcEwfKO19mOzbmJHySIYDFkE9IEsAvpgm1m0rDN+quqYqvrHqrq1ql6+nL2AuXLbrBtYTBbBTqtXWZTII9hJySKgD7aZRTs8+KmqXZP8P0mOTfKYJCdW1WN2dD+AHSGLgL6QR0AfyCJga8s54+cJSW5trX2ptfaDJFckecZ02gKYmCwC+kIeAX0gi4B7Wc7gZ78kty/6esPoMYDVJIuAvpBHQB/IIuBelnNx51risR+5MFhVPT/J85dxHIBxZBHQF515JIuAVSCLgHtZzuBnQ5K1i77+8SRf27qotfamJG9KXDEeWBGyCOiLzjySRcAqkEXAvSzno16fSnJAVf1kVd03yS8lee902gKYmCwC+kIeAX0gi4B72eEzflprd1XVC5P8TZJdk1zUWvv81DoDmIAsAvpCHgF9IIuArVVrq3dmn9MIYTCua60dOusmdpQsgsGQRUAfyCKgD7aZRcv5qBcAAAAAPWbwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQa2bdAAAAADA7e++9d2fNYYcd1llz+umnj13fZ599Ju5pnDPPPHPs+mWXXTaV4wyFM34AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgqrW2egerWr2DASvputbaobNuYkfJIhgMWQRTdOih3W+nD37wg2PXTznllM493vGOd0zc05yQRfTa7rvv3llzzTXXdNYcdNBBnTVVNXZ9WvOHjRs3jl1fu3btVI4zZ7aZRc74AQAAABgogx8AAACAgTL4AQAAABgogx8AAACAgTL4AQAAABgogx8AAACAgTL4AQAAABioNbNuAACm7fTTT++see5zn9tZc9xxx3XWbNy4caKegPmy6667dtY84AEPWPZxTjrppM6atWvXLvs4kzjllFM6a3bfffex61dfffW02gGSHHjggZ01p5122tj1I488snOPgw46aOKexvn+978/dn3dunWde1xxxRWdNTfccMPEPbHMwU9VrU/ynSR3J7mrtXboNJoC2F7yCOgDWQT0gSwCFpvGGT9Pba19Ywr7ACyXPAL6QBYBfSCLgCSu8QMAAAAwWMsd/LQkf1tV11XV86fREMAOkkdAH8gioA9kEfAflvtRryNaa1+rqocl+UBV3dxau9cV3UZBI2yAlTY2j2QRsEpkEdAHsgj4D8s646e19rXRf+9M8pdJnrBEzZtaa4e6oBiwkrrySBYBq0EWAX0gi4DFdnjwU1UPrKrd77mf5OeTfG5ajQFMSh4BfSCLgD6QRcDWlvNRr72T/GVV3bPP21prfz2VrgC2jzwC+kAWAX0gi4B72eHBT2vtS0n+yxR7Adgh8oitvfKVr+ysedCDHtRZ84hHPKKzZuPGjRP1xPDJomH5rd/6rc6as846axU6mS/PeMYzOmsuuOCCzpotW7ZMo52dkiyaHwceeGBnzR//8R931pxwwglj11trnXvccsstnTXr1q3rrDnvvPPGrvtz02z4ce4AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQa2bdAABM2+bNmztrHvSgB61CJ8As7L333mPXf+/3fq9zj2OPPXbZffzgBz/orNm0aVNnzf3ud7/Omj333HPs+r/+67927nH11Vd31rznPe8Zu37OOed07vHOd76zs+ab3/xmZw3Mu4svvriz5olPfGJnzS67jD+f47Of/WznHsccc0xnzcaNGztr6Cdn/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAM1JpZN8B0HHjggWPXjzvuuFXqpNsrX/nKzpo99thjFTpJdtmle/Z5ww03jF0/55xzOve44oorJu4JWL4/+7M/66z5kz/5k1XoBJiFX/3VXx27/hu/8Rude/zgBz/orDn77LPHrn/sYx/r3GPdunWdNb/yK7/SWfOWt7xl7Popp5zSucdll13WWdNl8+bNnTXf+973ln0cmAenn3762PVHP/rRnXu01jprvv71r49dn+Tvghs3buysYX454wcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAZqzawbGLrDDjts7PratWs79zjyyCM7a57znOeMXd9rr70695iGquqsaa1NpWYatmzZ0lnzuMc9buz6RRdd1LnHd77znc6adevWddYAAN3Wr1+/7D1e//rXd9a84hWvWPZxjjrqqM6a888/v7PmK1/5ytj1T37ykxP3tByXX375qhwHZm3vvffurPmd3/mdsevT+jtaVxZt2LBhKsdhfjnjBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABmpNV0FVXZTk+CR3ttYeO3psryRvT7J/kvVJfrG19q2Va3P1HX300Z01f/AHf9BZc8ABB4xd32uvvTr3qKrOmtZaZ81q+PjHPz7rFrbLz/7szy57j/ve976dNfe///2XfRx23jxi+5133nmdNVu2bOmsmSR/2fnIov678cYbl73HSSed1Fnz13/912PXr7nmms49zj333M6ar3zlK501T3va08auf+tbfjsOjSyarUn+DjDJ3/W6XHDBBZ01F1544bKPw7BNcsbPxUmO2eqxlyf5YGvtgCQfHH0NsNIujjwCZu/iyCJg9i6OLAIm0Dn4aa1dneSbWz38jCSXjO5fkuSZU+4L4EfII6APZBHQB7IImNSOXuNn79baxiQZ/fdh02sJYLvII6APZBHQB7II+BGd1/hZrqp6fpLnr/RxAMaRRUAfyCKgD2QR7Fx29IyfO6pq3yQZ/ffObRW21t7UWju0tXboDh4LYJyJ8kgWAStMFgF9IIuAH7Gjg5/3JrnnRx2clOQ902kHYLvJI6APZBHQB7II+BGdg5+qujzJ3yf5qaraUFUnJzk7yc9V1ReS/Nzoa4AVJY+APpBFQB/IImBSndf4aa2duI2lo6fcS6/stddenTVPfOITV6GTZMOGDZ01W7ZsGbv+ute9rnOP22+/feKetuXKK69c9h7T8uAHP7izZtOmTcs+zi233NJZ84lPfGLZx2HnzSO2X1cmJsn73ve+zprrr79+Gu0wMLKo//7t3/5t7PrmzZs795jkzxFve9vbxq5//vOf79zj8Y9/fGfNm9/85s6ab33rW501DIssmq1XvvKVnTVVtezj3HHHHcveA3b0o14AAAAA9JzBDwAAAMBAGfwAAAAADJTBDwAAAMBAGfwAAAAADJTBDwAAAMBAGfwAAAAADJTBDwAAAMBArZl1A331mc98prPmtttu66z58Ic/PHb9xhtv7Nzj/PPP76zZGT34wQ8eu/6BD3xgVfq4+OKLO2s2bNiw8o3ATmT//fdf9h6HH354Z80BBxzQWfP5z39+2b0A09X1Z7QTTzyxc4+3ve1tnTV77rnn2PUnPelJnXtcddVVnTUve9nLOmuA1XXyySd31rTWxq5v2rSpc4+/+Iu/mLgn2BZn/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwECtmXUDfXXLLbd01jzqUY9ahU52Tg9/+MM7a9atWzd2/XGPe1znHrvs0j37fPvb3z52/ZxzzuncA5iuF77whcveY5Kc/6d/+qdlHwfon7/5m7/prPnIRz7SWfPMZz5z2b3su+++nTX77LNPZ83mzZuX3Quw4MQTT1yV43zoQx/qrLnzzjtXoROGzhk/AAAAAANl8AMAAAAwUAY/AAAAAANl8AMAAAAwUAY/AAAAAANl8AMAAAAwUAY/AAAAAAO1ZtYNwFJOOOGEzpqf/umfHrveWuvc4+abb+6sefnLX95ZA8yfDRs2dNZs2rRpFToBVtsjH/nIzponP/nJq9BJ8jM/8zOdNaeddlpnzamnnjqNdoAk++yzz6xbmKrjjz++s+aAAw6YyrGuvvrqsevXXXfdVI7D9nHGDwAAAMBAGfwAAAAADJTBDwAAAMBAGfwAAAAADJTBDwAAAMBAGfwAAAAADJTBDwAAAMBAGfwAAAAADNSaWTfAzufoo4/urDn77LOXfZz169d31hxzzDGdNbfddtuyewEmt3bt2s6a008/fez6+eef37nHS17ykol7AubLbrvtNnb9rLPO6tzjIQ95SGfNpz71qbHrd999d+cehx12WGfNiSee2Fnz/ve/f+z6unXrOvcAJldVy97j4IMP7qz50Ic+1Flz1FFHjV1vrU3c03J973vfG7t+wQUXdO5x+eWXd9Z8+tOfHrt+1113de6xM+k846eqLqqqO6vqc4see1VVfbWqPj26PX1l2wR2drII6At5BPSBLAImNclHvS5OstRpEX/aWjt4dBv/TwwAy3dxZBHQDxdHHgGzd3FkETCBzsFPa+3qJN9chV4AtkkWAX0hj4A+kEXApJZzcecXVtVnR6cY7rmtoqp6flVdW1XXLuNYANsii4C+6MwjWQSsAlkE3MuODn5en+RRSQ5OsjHJudsqbK29qbV2aGvt0B08FsC2yCKgLybKI1kErDBZBPyIHRr8tNbuaK3d3VrbkuSCJE+YblsA3WQR0BfyCOgDWQQsZYcGP1W176Ivn5Xkc9uqBVgpsgjoC3kE9IEsApaypqugqi5P8pQkD62qDUl+P8lTqurgJC3J+iS/voI9AsgioDfkEdAHsgiYVLXWVu9gVat3MGZi7dq1nTVveMMbOmt+4Rd+obPmi1/84tj14447rnOPW2+9tbOGJV03z58Jl0X9NkmOfPnLXx67fv7553fu8dKXvnTinugtWcSSTjjhhLHrf/VXf9W5x80339xZc/jhh49dv/vuuzv3+MhHPtJZc8ghh3TWfPvb3x67fuih3W+Vrj9bsU2yaGAOPPDAzpqbbrqps2a1/q5dVb3oI1m9Xk499dSx62984xuncpw5s80sWs5P9QIAAACgxwx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAZqzawbYFjWr1/fWdNam8qxzjjjjLHrt95661SOAwD0x3777ddZc8kllyz7ONdee21nzbe//e1lH+e73/3usvdIkj322GPs+v3ud7+pHAd2BrfccsusW/gPk/Ty8Y9/fOz6hRdeOJVeDjnkkM6aY489duz605/+9Kn08ru/+7tj19/4xjdO5ThD4YwfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIFaM+sG6I/jjz++s+YlL3nJ2PVddumeJd58882dNa9//es7a6688srOGgBgWF70ohd11uyxxx5j1zdv3ty5x2tf+9qJe+qD22+/fez6JN8zMLkLL7yws+bkk09e9nHWrVvXWfOyl71s2ceZxCc+8YnOmgsuuGDs+tOf/vTOPd797nd31uy7775j10855ZTOPbp6HRJn/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwEAZ/AAAAAAMlMEPAAAAwECtmXUDrI6HPOQhnTW//du/3Vlz+OGHj13fsmVL5x6XXnppZ83rXve6zhoAYFge8IAHdNYcdthhyz7OJH/mue6665Z9nNV04YUXjl3/6le/ukqdwM7hfe97X2fNCSecMHb9YQ97WOceL37xiztrPvKRj4xdv+qqqzr3WC2Pf/zjO2uqatnH2W233Za9x5A44wcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAbK4AcAAABgoAx+AAAAAAZqTVdBVa1NcmmSfZJsSfKm1tprq2qvJG9Psn+S9Ul+sbX2rZVrlXGOPvrosevnnXde5x4HHXTQsvs44ogjOmuuv/76ZR+HnY8s2nm85jWv6aypqrHrH/3oR6fVDtyLLFpZe+yxR2fNk570pM6aL33pS2PX3/rWt07c03KcdtppnTWHHXZYZ83f/d3fddacffbZE/XEMMii2bvqqqs6ax772MeOXX/nO9/ZuceRRx7ZWXP55ZePXT/11FM797jllls6ayZxxhlnjF0/9thjO/dorS27j40bNy57jyGZ5Iyfu5K8pLX2n5McluTUqnpMkpcn+WBr7YAkHxx9DbBSZBHQB7II6ANZBEysc/DTWtvYWrt+dP87SW5Ksl+SZyS5ZFR2SZJnrlSTALII6ANZBPSBLAK2x3Zd46eq9k9ySJJPJtm7tbYxWQieJA+bdnMAS5FFQB/IIqAPZBHQpfMaP/eoqt2SvCvJb7bW/rnr+gqLnvf8JM/fsfYA7k0WAX0gi4A+kEXAJCY646eq7pOFQLmstfbu0cN3VNW+o/V9k9y51HNba29qrR3aWjt0Gg0DOy9ZBPSBLAL6QBYBk+oc/NTC2PjNSW5qrS3+0VDvTXLS6P5JSd4z/fYAFsgioA9kEdAHsgjYHpN81OuIJM9NcmNVfXr02CuSnJ3kHVV1cpKvJHn2yrQIkEQWAf0gi4A+kEXAxDoHP621a5Js68OiR0+3HZaydu3azpoXv/jFY9cPOuigzj2++MUvdtacccYZY9c/8YlPdO4BO0IWsVhrbez6e97jHzhZGbJoZb30pS+dyj5333332PUHPvCBnXu84AUv6Kz5pV/6pbHrhxxySOcea9Z0/zvsRz/60c6af//3f++sYThk0XzYtGnT2PVnP7t7Lvfud7+7s+ZJT3rS2PWLLrqoc49p6brOVNef4SZ15plnjl2/4oorpnKcodiun+oFAAAAwPww+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYqDWzboBu69ev76xprS37OGeccUZnzZVXXrns4wA7r+OPP76z5qlPfWpnzWtf+9pptAOssr322mvs+mmnnTaV4zz60Y8eu37bbbd17nH/+99/Kr10Oeusszpr/uiP/mgVOgFW26ZNmzprJvmz02te85qx6yeffPLEPa20devWddaceeaZnTU33HDDNNrZaTjjBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABsrgBwAAAGCgDH4AAAAABqpaa6t3sKrVO1hP7L777mPX3/ve93bu8ZSnPKWz5uabbx67fswxx3Tucdttt3XWwMh1rbVDZ93EjtoZs6gvPvaxj3XWPPrRj+6sOeKII8au33rrrRP3xFyTRXOmqsau//Iv/3LnHm9961un1c6yXX755WPXX/3qV3fu8YUvfKGzZsuWLRP3xEzIIqAPtplFzvgBAAAAGCiDHwAAAICBMvgBAAAAGCiDHwAAAICBMvgBAAAAGCiDHwAAAICBMvgBAAAAGKg1s25g6M4999yx609+8pM799iyZUtnzaWXXjp2/bbbbuvcA6APvv/973fW3HrrravQCTBtrbWx65dddlnnHpPUAAA/5IwfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYKIMfAAAAgIEy+AEAAAAYqDVdBVW1NsmlSfZJsiXJm1prr62qVyU5JcnXR6WvaK29f6Ua7aPdd9+9s+Ynf/Inl32cs88+u7Pm3HPPXfZxoM9k0TAcccQRs24BlkUWAX0gi4Dt0Tn4SXJXkpe01q6vqt2TXBfI8twAAAcpSURBVFdVHxit/Wlr7TUr1x7Af5BFQB/IIqAPZBEwsc7BT2ttY5KNo/vfqaqbkuy30o0BLCaLgD6QRUAfyCJge2zXNX6qav8khyT55OihF1bVZ6vqoqrac8q9ASxJFgF9IIuAPpBFQJeJBz9VtVuSdyX5zdbaPyd5fZJHJTk4C9PmJS8yU1XPr6prq+raKfQL7ORkEdAHsgjoA1kETGKiwU9V3ScLgXJZa+3dSdJau6O1dndrbUuSC5I8Yannttbe1Fo7tLV26LSaBnZOsgjoA1kE9IEsAibVOfipqkry5iQ3tdbOW/T4vovKnpXkc9NvD2CBLAL6QBYBfSCLgO0xyU/1OiLJc5PcWFWfHj32iiQnVtXBSVqS9Ul+fUU6BFggi4A+kEVAH8giYGKT/FSva5LUEkvvn347AEuTRUAfyCKgD2QRsD0mOeOHbTjooIM6a5761Kcu+zhnnHHGsvcAAAAAdj7b9ePcAQAAAJgfBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA2XwAwAAADBQBj8AAAAAA1WttdU7WNXXk9y26KGHJvnGqjWwfPPUr15Xzjz1u1K9/kRr7cdWYN9VIYtWlV5Xzjz1K4uWsEQWJX5dV8o89ZrMV796lUWzpteVM0/96nVMFq3q4OdHDl51bWvt0Jk1sJ3mqV+9rpx56neeep2leXud5qlfva6ceep3nnqdtXl6rfS6cuapX70O0zy9VnpdOfPUr17H81EvAAAAgIEy+AEAAAAYqFkPft404+Nvr3nqV68rZ576nadeZ2neXqd56levK2ee+p2nXmdtnl4rva6ceepXr8M0T6+VXlfOPPWr1zFmeo0fAAAAAFbOrM/4AQAAAGCFzGzwU1XHVNU/VtWtVfXyWfUxiapaX1U3VtWnq+raWfeztaq6qKrurKrPLXpsr6r6QFV9YfTfPWfZ4z220eurquqro9f301X19Fn2eI+qWltVH6qqm6rq81X1otHjvXttx/Tay9e2T2TR9MiilSGLdg6yaHpk0cqYpyxK5NGOmqcsSvqdR7JoZciiHexjFh/1qqpdk9yS5OeSbEjyqSQnttb+YdWbmUBVrU9yaGvtG7PuZSlVdWSS7ya5tLX22NFj5yT5Zmvt7FFo79la++1Z9jnqa6leX5Xku62118yyt61V1b5J9m2tXV9Vuye5Lskzk/xaevbajun1F9PD17YvZNF0yaKVIYuGTxZNlyxaGfOURYk82hHzlkVJv/NIFq0MWbRjZnXGzxOS3Npa+1Jr7QdJrkjyjBn1Mvdaa1cn+eZWDz8jySWj+5dk4TfXzG2j115qrW1srV0/uv+dJDcl2S89fG3H9Mp4smiKZNHKkEU7BVk0RbJoZcxTFiXyaAfJoimSRStDFu2YWQ1+9kty+6KvN6TfQdyS/G1VXVdVz591MxPau7W2MVn4zZbkYTPup8sLq+qzo9MMe3Fa3mJVtX+SQ5J8Mj1/bbfqNen5aztjsmjl9fr9soRev19k0WDJopXX6/fLEnr9fpmnLErk0XaYtyxK5i+Pev9+2Uqv3yuyaHKzGvzUEo/1+ceLHdFae3ySY5OcOjoVjul5fZJHJTk4ycYk5862nXurqt2SvCvJb7bW/nnW/YyzRK+9fm17QBaxWK/fL7Jo0GQRi/X6/TJPWZTIo+00b1mUyKOV1Ov3iizaPrMa/GxIsnbR1z+e5Gsz6qVTa+1ro//emeQvs3AaZN/dMfo84T2fK7xzxv1sU2vtjtba3a21LUkuSI9e36q6TxbeoJe11t49eriXr+1Svfb5te0JWbTyevl+WUqf3y+yaPBk0crr5ftlKX1+v8xTFiXyaAfMVRYlc5lHvX2/bK3P7xVZtP1mNfj5VJIDquonq+q+SX4pyXtn1MtYVfXA0UWYUlUPTPLzST43/lm98N4kJ43un5TkPTPsZax73qAjz0pPXt+qqiRvTnJTa+28RUu9e2231WtfX9sekUUrr3fvl23p6/tFFu0UZNHK6937ZVv6+n6ZpyxK5NEOmpssSuY2j3r5fllKX98rsmgH+2gz+KleSVILP67s/CS7JrmotXbWTBrpUFWPzML0OEnWJHlb33qtqsuTPCXJQ5PckeT3k/xVknckeUSSryR5dmtt5hfs2kavT8nCKW4tyfokv37P5zNnqaqelOSjSW5MsmX08Cuy8JnMXr22Y3o9MT18bftEFk2PLFoZsmjnIIumRxatjHnKokQe7ah5yaKk/3kki1aGLNrBPmY1+AEAAABgZc3qo14AAAAArDCDHwAAAICBMvgBAAAAGCiDHwAAAICBMvgBAAAAGCiDHwAAAICBMvgBAAAAGCiDHwAAAICB+v8B/zHodFSztWAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at some of the original images:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model:\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# our first dense layer\n",
    "model.add(Dense(1028, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model.add(Dense(1028, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1028)              806980    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1028)              1057812   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10290     \n",
      "=================================================================\n",
      "Total params: 1,875,082\n",
      "Trainable params: 1,875,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model:\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 25s 416us/sample - loss: 1.0370 - accuracy: 0.7776\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 25s 410us/sample - loss: 0.4281 - accuracy: 0.8892\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.3448 - accuracy: 0.9056\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 20s 342us/sample - loss: 0.3063 - accuracy: 0.9145\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 21s 351us/sample - loss: 0.2812 - accuracy: 0.9212\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 21s 346us/sample - loss: 0.2620 - accuracy: 0.9267\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 22s 360us/sample - loss: 0.2463 - accuracy: 0.9315\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 20s 340us/sample - loss: 0.2324 - accuracy: 0.9341\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 23s 391us/sample - loss: 0.2204 - accuracy: 0.9381\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 23s 379us/sample - loss: 0.2097 - accuracy: 0.9414\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.1999 - accuracy: 0.9438\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.1911 - accuracy: 0.9464\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.1828 - accuracy: 0.9487\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.1753 - accuracy: 0.9510\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.1685 - accuracy: 0.9524\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 21s 352us/sample - loss: 0.1619 - accuracy: 0.9549\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 21s 351us/sample - loss: 0.1559 - accuracy: 0.9565\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.1503 - accuracy: 0.9578\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 20s 342us/sample - loss: 0.1450 - accuracy: 0.9591\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 22s 367us/sample - loss: 0.1401 - accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148030610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting verbose=1 prints out some results after each epoch\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.14314549036175012\n",
      "Test accuracy: 0.9585\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing score:\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set accuracy of our model is almost 96%. This is quite a very good result! Let's play with our model, specifically with the model's hyperparameters to see if we can improve our result.\n",
    "\n",
    "### Second model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "# our first dense layer\n",
    "model1.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model1.add(Dense(16, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model1.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 25,818\n",
      "Trainable params: 25,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 1.3724 - accuracy: 0.5854\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6659 - accuracy: 0.8188\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4817 - accuracy: 0.8677\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4040 - accuracy: 0.8872\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3623 - accuracy: 0.8974s - loss: 0.3\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3352 - accuracy: 0.9047\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3158 - accuracy: 0.9097\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3006 - accuracy: 0.9142\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2879 - accuracy: 0.9186\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2769 - accuracy: 0.9212\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2675 - accuracy: 0.9237\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2588 - accuracy: 0.9263\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2512 - accuracy: 0.9291\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2443 - accuracy: 0.9308\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2376 - accuracy: 0.9330\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2317 - accuracy: 0.9342\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2259 - accuracy: 0.9364\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2206 - accuracy: 0.9381\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2159 - accuracy: 0.9392\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2108 - accuracy: 0.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1548f5650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting verbose=1 prints out some results after each epoch\n",
    "model1.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.20947346605658532\n",
      "Test accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second model has the same number of layer as our first model, but has less neurons. Our second model took a lot less time to execute, but has a smaller accuracy compared to the first model.\n",
    "\n",
    "### Third model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# our first dense layer\n",
    "model2.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
    "# our second dense layer\n",
    "model2.add(Dense(512, activation=\"relu\"))\n",
    "# our third dense layer\n",
    "model2.add(Dense(256, activation=\"relu\"))\n",
    "# our fourth dense layer\n",
    "model2.add(Dense(128, activation=\"relu\"))\n",
    "# our fifth dense layer\n",
    "model2.add(Dense(64, activation=\"relu\"))\n",
    "# last layer is the output layer.\n",
    "model2.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,501,770\n",
      "Trainable params: 1,501,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 372us/sample - loss: 1.1635 - accuracy: 0.7113\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.3533 - accuracy: 0.9013\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.2741 - accuracy: 0.9218\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.2337 - accuracy: 0.9320\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 18s 308us/sample - loss: 0.2047 - accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.1813 - accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.1627 - accuracy: 0.9525\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 0.1479 - accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.1340 - accuracy: 0.9611\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 19s 311us/sample - loss: 0.1220 - accuracy: 0.9646\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 0.1114 - accuracy: 0.9678\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.1023 - accuracy: 0.9711\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.0941 - accuracy: 0.9728\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.0869 - accuracy: 0.9754\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.0798 - accuracy: 0.9776\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.0743 - accuracy: 0.9791\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.0686 - accuracy: 0.9804\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.0636 - accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 18s 292us/sample - loss: 0.0589 - accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0548 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153d2acd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting verbose=1 prints out some results after each epoch\n",
    "model2.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.08257538281586022\n",
      "Test accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third model has 3 more layer of neurons. It took a bit longer to execute, but increased our accuracy by 2%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
